---
title: "3 Correlation"
output: html_document
---

Julien Emile-Geay

Correlating a non-annual, time uncertain record is dangerous. With 3 main pitfalls.
Any one of these pitfalls will be enough to doom a correlation fishing experiment.

Also pitfall 0 - correlatio is not causation 
## Pitfall 1 Persistence

Classical t test for correlation

$$
T = r \sqrt{\frac{v-2}{1-r^2}}
$$
Autocorrelation can reduce the degrees of freedom - but a t-test assumes each measurement is independent.

Autoregressive:
$$
X_t = \gamma X_{t-1} + \epsilon_t \\
\epsilon_t \sim  N(0, \sigma_2)
$$


*Persistence lowers the degrees of freedom.* Around 0.6 correlation this really begins to increase the p-value (examples r = 0.3, between two AR(1) time series (500 samples)).

You can take the degrees of freedom into account. There is a parametric way and not always ideal, but can work.

## Pitfall 2 - Test Multiplicity

A test with 5% type 1 error - if you do this 20 times you will find something spurious!
P-hacking has a cure: False discovery rate.

$$
\alpha = \text{false positive rate} = 
\dfrac{\text{#falsely rejected hyp}}{\text{#number of hyp}}
$$
Have to be below the line.

## Pitfall 3 - Age uncertainties 

Members of an ensemble can be very different (still 20 years in a high resoltuion dataset in an instrumental period)

Some ensemble members look very enticing
The areas that have the most uncertainty might look very similarly to the areas with most correlation.

# Dealing with it in GeoChronR
https://nickmckay.github.io/GeoChronR/articles/correlation.html

`corEns`

- binning
- ensembles
- isopersistent
- isospectral
  - ebisuzaki is the same thing
  - randomise the phase to that the spectra are the same, but compute the correlation against this
- gaussianise
   - true by default 
   - guard against distrubtions that are highly non-gaussian
   
## Aligning times
Binning a conservative strategy way of doing this


If you get a low fraction signficant that's a clue